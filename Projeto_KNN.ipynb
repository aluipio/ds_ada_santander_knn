{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QZlhEeVhsr0O",
        "7IZUR66bUFT3",
        "9OKdXKO4h43f",
        "wJVMHrcJVGFB",
        "trN6DPGpUthm",
        "bDWxbR8LiDH8",
        "sXWnBSF_UWfK"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **KNN Lib ® 2024**\n",
        "\n",
        " **Algoritmo de K-Nearest Neighbors - KNN**\n",
        "\n",
        "![KNN](https://github.com/aluipio/ds_ada_santander_knn/blob/main/images/ds_ml_ada.png?raw=true)\n",
        "\n",
        "***1. Do objetivo:***\n",
        "\n",
        "O objetivo deste projeto é recriar o algoritmo do KNN para calcular e classificar um dataset específico.\n",
        "\n",
        "\n",
        "***2. Das limitações:***\n",
        "\n",
        "Ficando restrito a ementa do curso Santander Coders - ADA Tech, não foram utilizados:\n",
        "* Recursos avançados;\n",
        "* Orientação a Objetos;\n",
        "* Lib estrangeiras: Pandas, Numpy ou Scikit Learning;\n",
        "\n",
        "\n",
        "***3. Referências (ou materiais consultados):***\n",
        "\n",
        "Artificial Intelligence. (2024, 3 de Janeiro). What are the most effective distance metrics for optimizing k-nearest neighbors algorithms? Linkedin.com; www.linkedin.com. https://www.linkedin.com/advice/3/what-most-effective-distance-metrics-optimizing-xndwc.\n",
        "\n",
        "Bruce, P., & Bruce, A. (2019). Estatística prática para cientistas de dados: 50 conceitos essenciais. Alta Books.\n",
        "\n",
        "de Maquina, A. [@aprendizagemdemaquina9452]. (2021, March 4). O que é o KNN e como implementar do zero. Youtube. Acesso em 20 Jan 2024 de https://www.youtube.com/watch?v=E7R6O4Aqw-M.\n",
        "\n",
        "Comunidade Ada. (n.d.). Ada.Tech. Acesso em 18 Jan 2024 de https://lms.ada.tech/student.\n",
        "\n",
        "Fávero, L. P., Lopes E, B., & Prado, P. (2017). Manual de análise de dados: estatística e modelagem multivariada com Excel, SPSS e Stata. Elsevier.\n",
        "\n",
        "Kadiwal, A. (2021). Water Quality [Data set]. In Drinking Water Potability. Acesso em 12 Jan 2024 de  https://www.kaggle.com/datasets/adityakadiwal/water-potability/data.\n",
        "\n",
        "Kaggle: Your machine learning and data science community. (n.d.). Kaggle.com. Acesso em 20 Jan 2024 de https://www.kaggle.com.\n",
        "\n",
        "Kunumi. (2020, 10 Junho). Métricas de Avaliação em Machine Learning: Classificação. Kunumi Blog. Acesso em 17 Jan 2024 de https://medium.com/kunumi/m%C3%A9tricas-de-avalia%C3%A7%C3%A3o-em-machine-learning-classifica%C3%A7%C3%A3o-49340dcdb198.\n",
        "\n",
        "Matos, G. (2023, December 5). K-Nearest Neighbors(KNN): Entendendo o seu funcionamento e o construindo do zero. Share! Por Ateliê de Software. Acesso em 18 Jan 2024 de https://share.atelie.software/k-nearest-neighbors-knn-entendo-o-seu-funcionamento-e-o-construindo-do-zero-a21b022acd6f.\n",
        "\n",
        "PEP 257 – docstring conventions. (n.d.). Python.org. Acesso em 23 Jan 2024 de vhttps://peps.python.org/pep-0257.\n",
        "\n",
        "Srivastava, T. (2018, 25 março). A complete guide to K-Nearest Neighbors (updated 2024). Analytics Vidhya. Acesso em 24 Jan 2024 de https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering.\n",
        "\n",
        "Tavares, C. (2019, 26 Março). KNN sem caixa preta. Medium. Acesso em 22 Jan 2024 de https://medium.com/@caroli.agro/aplicando-knn-em-iris-dataset-d594b79652d1.\n",
        "\n",
        "Yu, C., Ooi, B. C., Tan, K., & Jagadish, H. V. (2001). Indexing the Distance: An Efficient Method to KNN Processing. In Very Large Data Bases Conference.\n",
        "\n",
        "\n",
        "***4. Integrantes do grupo:***\n",
        "* Anderson Miranda - ID: 1116003\n",
        "* André Kuster - ID: 1116029\n",
        "* Arthur Steins - ID: 1116023\n",
        "* João Souza - ID:\n",
        "* Juliana Bertolucci Peixoto - ID: 1116030"
      ],
      "metadata": {
        "id": "U4kTC2CAsK2D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Core Functions**"
      ],
      "metadata": {
        "id": "QZlhEeVhsr0O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functions Files"
      ],
      "metadata": {
        "id": "7IZUR66bUFT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv"
      ],
      "metadata": {
        "id": "LJle_hBPg8gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Criar arquivo CSV com dados\n",
        "###########################################\n",
        "def create_csv(data, name:str = 'data.csv', delimiter: str = ';'):\n",
        "    '''\n",
        "    Creates a CSV file from the input data.\n",
        "\n",
        "    It takes a dictionary or a list of lists as input and writes it to a CSV file.\n",
        "\n",
        "    The name of the file and the delimiter can be specified.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data: dict or list of lists\n",
        "            The to-be-written-to-the-CSV-file input data.\n",
        "            The keys will be used as column headers if it's a dictionary.\n",
        "        name: str, optional\n",
        "            The to-be-created CSV file's name\n",
        "            The default is 'data.csv'.\n",
        "        delimiter: str, optional\n",
        "            The used character to separate values in the CSV file.\n",
        "            The default to ';'.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input data is not a dictionary or a list of lists.\n",
        "    '''\n",
        "    # Cria o Arquivo CSV\n",
        "    _name = str(name) if '.csv' in str(name) else str(name) + '.csv'\n",
        "    _archive = open(_name, 'w')\n",
        "\n",
        "    # Escreve no Arquivo CSV\n",
        "    _escritor = csv.writer(_archive, delimiter=';', lineterminator='\\n')\n",
        "    _data_table = dict_to_list(data) if type(data) == dict else data\n",
        "    _escritor.writerows(_data_table)\n",
        "\n",
        "    # fecha e salva o arquivo\n",
        "    _archive.close()"
      ],
      "metadata": {
        "id": "61CTydrEOvvo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Ler arquivo CSV\n",
        "###########################################\n",
        "def read_csv(name, delimiter=',', tipo=None):\n",
        "    '''\n",
        "    Reads a CSV file and returns the data.\n",
        "\n",
        "    It takes the name of a CSV file, a delimiter, and an optional type as input; reads the CSV file and returns the data in the specified type.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        name: str\n",
        "            The to-be-read CSV file name.\n",
        "        delimiter: str, optional\n",
        "            The used character to separate values in the CSV file.\n",
        "            Defaults to ','.\n",
        "        tipo: type, optional\n",
        "            The type to which the data should be converted.\n",
        "            If not specified, the function will infer the type based on the data.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        dict or list of lists\n",
        "            The CSV file data converted to the specified type.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        FileNotFoundError\n",
        "            If the specified CSV file does not exist.\n",
        "    '''\n",
        "\n",
        "    # Verifica nome do arquivo\n",
        "    _name = str(name) if '.csv' in str(name) else str(name) + '.csv'\n",
        "\n",
        "    try:\n",
        "        with open(_name, 'r') as arquivo:\n",
        "            data_reader = csv.reader(arquivo, delimiter=delimiter, lineterminator='\\n')\n",
        "            header = next(data_reader)\n",
        "            data_dict = {col: [] for col in header}\n",
        "\n",
        "            for row in data_reader:\n",
        "                for col, value in zip(header, row):\n",
        "                    data_dict[col].append(convert_value(value))\n",
        "\n",
        "        return data_dict\n",
        "\n",
        "    except FileNotFoundError as e:\n",
        "        raise FileNotFoundError(f\"Arquivo CSV '{_name}' não encontrado.\") from e\n",
        "\n",
        "    except csv.Error as e:\n",
        "        raise ValueError(f\"Erro ao ler o arquivo CSV '{_name}': {e}\") from e"
      ],
      "metadata": {
        "id": "fRQt6fhBKiAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Converte dicionário para lista\n",
        "###########################################\n",
        "def dict_to_list(data):\n",
        "    '''\n",
        "    Converts a dictionary into a list of lists.\n",
        "\n",
        "    If the input data is a dictionary, the function converts it into a list of lists where the first list is the dictionary's keys, and the subsequent lists are the values from each key.\n",
        "    If the input data is already a list, the function returns the input list.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data: dict or list\n",
        "            The input data (dictionary or a list).\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        list\n",
        "            A list of lists representing the input data (if a dictionary).\n",
        "            The input list (if a list).\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input data is not a dictionary or a list.\n",
        "    '''\n",
        "\n",
        "    if type(data) == dict:\n",
        "        _info = data_info(data)\n",
        "        _num_rows = _info['num_rows']\n",
        "        _data_table = [_info['columns']]\n",
        "        _data_table.extend([data_row(data, i) for i in range(_info['num_rows'])])\n",
        "        return _data_table\n",
        "    elif type(data) == list:\n",
        "        return data\n",
        "    else:\n",
        "        raise TypeError('Input data must be a dictionary or a list.')"
      ],
      "metadata": {
        "id": "2-fpQy-yK7XD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Converte lista de listas para dicionário\n",
        "###########################################\n",
        "def list_to_dict(data):\n",
        "    '''\n",
        "    Converts a list into a dictionary.\n",
        "\n",
        "    If the input data is a list, the function converts it into a dictionary where the keys are the first list's elements, and the values are the corresponding elements from the subsequent lists.\n",
        "    If the input data is already a dictionary, the function returns the input dictionary.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data: list or dict\n",
        "            The input data. It can be a list or a dictionary.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        dict\n",
        "            A dictionary representing the input data.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input data is not a list or a dictionary.\n",
        "    '''\n",
        "    if type(data) == list:\n",
        "        return {name:[row[i] for row in data[1:]] for i, name in zip(range(len(data[0])), data[0])}\n",
        "    elif type(data) == dict:\n",
        "        return data\n",
        "    else:\n",
        "      raise TypeError('Input data must be a dictionary or a list.')"
      ],
      "metadata": {
        "id": "yMjRinYBQSLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functions Dataset"
      ],
      "metadata": {
        "id": "9OKdXKO4h43f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Apresenta uma leitura do Dataset\n",
        "###########################################\n",
        "def data_info(data):\n",
        "    '''\n",
        "    Return a dictionary with information about the input data.\n",
        "\n",
        "    The returned dictionary includes the following keys:\n",
        "        - 'columns': list of keys from the input dictionary.\n",
        "        - 'num_columns': number of keys in the input dictionary.\n",
        "        - 'num_rows': the list associated with the first key's length in the input dictionary.\n",
        "        - 'dimension': a tuple with the columns' and rows' number.\n",
        "        - 'info_col_{column_name}': a tuple with the null values and the type of values' number in the column.\n",
        "\n",
        "    If the column contains varied types, the type will be returned as 'mixed'.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "    data: dict\n",
        "        The input dictionary.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        dict\n",
        "            A dictionary with the input data's information.\n",
        "        '''\n",
        "\n",
        "    # Verificação de tipo de data inserido (type checking)\n",
        "    if not isinstance(data, dict):\n",
        "        raise TypeError('Input data must be a dictionary.')\n",
        "\n",
        "    _info = {}\n",
        "    _data = data\n",
        "    _info['columns'] = list(_data.keys())\n",
        "    _info['num_columns'] = len(_data)\n",
        "    _info['num_rows'] = len(_data[_info['columns'][0]])\n",
        "    _info['dimension'] = (_info['num_columns'], _info['num_rows'])\n",
        "\n",
        "    for _col in _data.keys():\n",
        "        _var_null = _data[_col].count(\"\")\n",
        "        _var_type = str(type(_data[_col][0]))\n",
        "        for _ in _data[_col]:\n",
        "            if str(type(_)) != _var_type:\n",
        "                _var_type = 'mixed'\n",
        "\n",
        "        _info[f'info_col_{_col[:20]:_>20}'] = (f\"null  {_var_null:>4}\",f\"type   {_var_type:>6}\")\n",
        "\n",
        "    return _info"
      ],
      "metadata": {
        "id": "--_Lx5rzAZis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Descreve os dados\n",
        "###########################################\n",
        "def data_describe(data):\n",
        "    '''\n",
        "    Describes the data in the input dictionary.\n",
        "\n",
        "    It ierates over each dictionary's column, calculates various statistics, and returns a string that describes the data.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data: dict\n",
        "        The input dictionary. Each key represents a column, and the corresponding value is a list of data for that column.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        str\n",
        "        A string that describes the data, including the type, quantity, maximum, minimum, sum, range, mean, and median for each dictionary's column.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input data is not a dictionary.\n",
        "    '''\n",
        "\n",
        "    # Verificação de tipo de data inserido (type checking)\n",
        "    if not isinstance(data, dict):\n",
        "        raise TypeError('Input data must be a dictionary.')\n",
        "\n",
        "    _data = data\n",
        "\n",
        "    # Verifica o tipo de cada variável\n",
        "    _info = {}\n",
        "    for _col in _data.keys():\n",
        "        _type = type(_data[_col][0])\n",
        "        for _ in _data[_col]:\n",
        "            if type(_) != _type:\n",
        "                _type = 'mixed'\n",
        "        _info[_col] = _type\n",
        "\n",
        "    _var = [f\"{'Analysis':<12}\"]\n",
        "    _var += [_col for _col in _data.keys() if _info[_col] not in ['mixed', str]] + ['\\n']\n",
        "    _var += [f\"{'Tipo':<12}\"] + [str(_info[_col]) for _col in _data.keys() if _info[_col] not in ['mixed', str]] + ['\\n']\n",
        "    _var += [f\"{'Quant':<12}\"] + [len(_data[_col]) for _col in _data.keys() if _info[_col] not in ['mixed', str]] + ['\\n']\n",
        "    _var += [f\"{'Máximo':<12}\"] + [round(max(_data[_col]), 5) for _col in _data.keys() if _info[_col] not in ['mixed', str]] + ['\\n']\n",
        "    _var += [f\"{'Mínimo':<12}\"] + [round(min(_data[_col]), 5) for _col in _data.keys() if _info[_col] not in ['mixed', str]] + ['\\n']\n",
        "    _var += [f\"{'Soma':<12}\"] + [round(sum(_data[_col]), 5) for _col in _data.keys() if _info[_col] not in ['mixed', str]] + ['\\n']\n",
        "    _var += [f\"{'Amplitude':<12}\"] + [round(max(_data[_col])-min(_data[_col]), 5) for _col in _data.keys() if _info[_col] not in ['mixed', str]] + ['\\n']\n",
        "    _var += [f\"{'Média':<12}\"] + [round(sum(_data[_col])/len(_data[_col]), 5) for _col in _data.keys() if _info[_col] not in ['mixed', str]] + ['\\n']\n",
        "    _var += [f\"{'Mediana':<12}\"] + [round(sorted(_data[_col])[int(len(_data[_col])/2)], 5) for _col in _data.keys() if _info[_col] not in ['mixed', str]] + ['\\n']\n",
        "\n",
        "    return \"\".join([f'{str(_)[:20]:>20}' for _ in _var])"
      ],
      "metadata": {
        "id": "yFJCQmlq8D86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Retorna dados de uma linha\n",
        "###########################################\n",
        "def data_row(data, row: int = 0):\n",
        "    '''\n",
        "    Returns a list of values from the specified row in the input dictionary.\n",
        "\n",
        "    The function retrieves the values from the specified row across all columns in the dictionary. If the selected row index exceeds the number of rows in the dictionary, the function retrieves the values from the last row.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data: dict\n",
        "            The input dictionary.\n",
        "            Each key represents a column, and the corresponding value is a data list for that column.\n",
        "        row: int, optional\n",
        "            The index of the row to retrieve the values from.\n",
        "            The default is 0.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        list\n",
        "            A list of values from the specified row in the dictionary.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input data is not a dictionary.\n",
        "    '''\n",
        "\n",
        "    #Verificação de tipo de data inserido (type checking)\n",
        "    if not isinstance(data, dict):\n",
        "        raise TypeError(\"Input data must be a dictionary.\")\n",
        "\n",
        "    _columns = list(data.keys())\n",
        "    _num_rows = len(data[_columns[0]])\n",
        "    _row = int(row) if int(row) < _num_rows else _num_rows - 1\n",
        "\n",
        "    return [data[col][_row] for col in _columns]"
      ],
      "metadata": {
        "id": "7a6ZHhiOHaht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###################################################\n",
        "# Retorna coluna de dados em formato especificado\n",
        "###################################################\n",
        "def data_col(data, column:str, tipo = list):\n",
        "    '''\n",
        "    Returns the data of a specified column in the desired format.\n",
        "\n",
        "    The function retrieves the specified column data in the dictionary and returns it in the format specified by the 'type' parameter.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data: dict\n",
        "        The input dictionary. Each key represents a column, and the corresponding value is a list of data for that column.\n",
        "        column: str\n",
        "        The name of the column from which data will be retrieved from.\n",
        "        tipo: type, optional\n",
        "        The desired format for the returned data. It can be a list (default), tuple, or dict.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        list, tuple, or dict\n",
        "        The data from the specified column is now in the desired format. If the specified column does not exist in the dictionary, the function returns None.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input data is not a dictionary.\n",
        "    '''\n",
        "    # Verificação de tipo de data inserido (type checking)\n",
        "    if not isinstance(data, dict):\n",
        "        raise TypeError(\"Input data must be a dictionary.\")\n",
        "\n",
        "    if type == tuple:\n",
        "        return (column, data[column]) if column in data.keys() else None\n",
        "    if type == dict:\n",
        "        return {column : data[column]} if column in data.keys() else None\n",
        "    else:\n",
        "        return [column, data[column]] if column in data.keys() else None"
      ],
      "metadata": {
        "id": "2VaJ5xt1MlgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Quantidade por tipo\n",
        "###########################################\n",
        "def data_value_counts(data, col:str = \"\"):\n",
        "    '''\n",
        "    Counts each unique value's occurrence in the specified column or list.\n",
        "\n",
        "    If the input data is a dictionary, the function counts each unique value's occurrence in the specified column.\n",
        "    If it is a list, the function calculates each unique occurrence value in the list.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data: dict or list\n",
        "            The input data. It can be a list of data or a dictionary (each key represents a column, and the corresponding value is a list of data for that column).\n",
        "        col: str, optional\n",
        "            The column to count the unique values in.\n",
        "            This parameter is ignored if the input data is a list.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        dict:\n",
        "            A dictionary where each key is a unique value from the specified column or list, and each value is its count.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input data is not a dictionary or a list.\n",
        "    '''\n",
        "    # Verificação de tipo de data inserido (type checking)\n",
        "    if not isinstance(data, dict) and not isinstance(data, list):\n",
        "        raise TypeError('Input data must be a dictionary or list.')\n",
        "\n",
        "    if type(data) == dict:\n",
        "        if col in list(data.keys()):\n",
        "            _set = {_ for _ in data[col]}\n",
        "            return dict(sorted({name : data[col].count(name) for name in _set}.items(), key=lambda x: x[1]))\n",
        "    elif type(data) == list:\n",
        "        _set = {_ for _ in data}\n",
        "        return dict(sorted({name : data.count(name) for name in _set}.items(), key=lambda x: x[1]))\n",
        "    else:\n",
        "        return None"
      ],
      "metadata": {
        "id": "jvqqYF-wGvyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Retorna conjunto em serie\n",
        "###########################################\n",
        "def data_serie(data, row: int = 0):\n",
        "    '''\n",
        "    Returns a dictionary that represents a row of data from the input dictionary.\n",
        "\n",
        "    The function retrieves the values from the specified row across all columns in the dictionary. It returns a dictionary with column names as the keys and corresponding values from the specified row as the values.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data: dict\n",
        "            The input dictionary. Each key represents a column, and the corresponding value is a list of data for that column.\n",
        "        column: str\n",
        "            The column's name from which data will be retrieved.\n",
        "        row: int, optional\n",
        "            The row's index to retrieve the values from. The default is 0.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        dict:\n",
        "            A dictionary that represents a row of data from the input dictionary.\n",
        "            The keys are the column names, and the values are the corresponding values from the specified row.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input data is not a dictionary.\n",
        "    '''\n",
        "    #Verificação de tipo de data inserido (type checking)\n",
        "    if not isinstance(data, dict):\n",
        "        raise TypeError('Input data must be a dictionary.')\n",
        "\n",
        "    _info = data_info(data)\n",
        "\n",
        "    return dict(zip(_info['columns'], data_row(data, row)))"
      ],
      "metadata": {
        "id": "IDRV1Us3KKib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Visualiza o dataset\n",
        "###########################################\n",
        "def data_view(data, limit: int = 10):\n",
        "    '''\n",
        "    Prints a data's formatted view up to the specified limit.\n",
        "\n",
        "    The function retrieves the input dictionary's values and prints a formatted data view up to the specified limit.\n",
        "    The view includes the column names and the values from each row up to the limit.\n",
        "    If the limit is less than the number of rows in the data, the function also indicates fewer rows than the function's limit.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data: dict\n",
        "                The input dictionary. Each key represents a column, and the corresponding value is a data list for that column.\n",
        "        limit: int, optional\n",
        "            The maximum number of rows to display.\n",
        "            The default is 10.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input data is not a dictionary.\n",
        "    '''\n",
        "\n",
        "    # Verificação de tipo de data inserido (type checking)\n",
        "    if not isinstance(data, dict):\n",
        "        raise TypeError(\"Input data must be a dictionary.\")\n",
        "\n",
        "    _data = data.copy()\n",
        "    info = data_info(_data)\n",
        "\n",
        "    row_title = f\"|{'n':^5}|\"\n",
        "    row_title += \"\".join([f\"{col[0:6]:^11}|\" for col in info['columns']])\n",
        "\n",
        "    print('-'*len(row_title))\n",
        "    print(f'|{\"VIEW DATASET\":^{len(row_title)-2}}|')\n",
        "    print('-'*len(row_title))\n",
        "\n",
        "    print(row_title)\n",
        "    print('-'*len(row_title))\n",
        "\n",
        "    for i in range(info['num_rows'] if limit > info['num_rows'] else limit):\n",
        "        row_set = f\"|{i:^5}|\"\n",
        "        row_set += \"\".join([f\"{str(_data[col][i])[:9]:^11}|\" for col in info['columns']])\n",
        "        print(row_set)\n",
        "\n",
        "    if limit < info['num_rows']:\n",
        "        row_set = f\"|{'..':^5}|\"\n",
        "        row_set += \"\".join([f\"{'...':^11}|\" for _ in info['columns']])\n",
        "        print(row_set)\n",
        "\n",
        "    print('-'*len(row_title))\n",
        "    dimension = info['dimension']\n",
        "    print(f'|{f\"  col/row: {dimension} | limit view: {limit}\":<{len(row_title)-2}}|')\n",
        "    print('-'*len(row_title))"
      ],
      "metadata": {
        "id": "qH43BoFAwVSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Identifica e converte valor\n",
        "###########################################\n",
        "def convert_value(value):\n",
        "    '''\n",
        "    Converts a value to a specific type.\n",
        "\n",
        "    It takes a value as input and converts it to a specific type based on the value itself.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        value: str\n",
        "            The value to be converted.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        int, float, or str\n",
        "            The converted value.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        ValueError\n",
        "            If the value cannot be converted to int or float.\n",
        "    '''\n",
        "\n",
        "    if value.isalpha():\n",
        "        return str(value)\n",
        "    elif value.isnumeric():\n",
        "        return int(value)\n",
        "    elif '.' in value and value.replace('.', '').isnumeric():\n",
        "        return float(value)\n",
        "    else:\n",
        "        return str(value)"
      ],
      "metadata": {
        "id": "hCBmYcvWRWtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Deletar Atributo do dicionário\n",
        "###########################################\n",
        "def data_drop_attribute(data, drop):\n",
        "    '''\n",
        "    Removes a key-value pair from the input dictionary.\n",
        "\n",
        "    The function takes a dictionary and a string as input removes the key-value pair from the dictionary (the key matches the provided string) and returns the modified dictionary.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data: dict\n",
        "            The input dictionary.\n",
        "        drop: str\n",
        "            The key to be removed from the dictionary.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        dict\n",
        "            The modified dictionary (with the specified key-value pair removed).\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input data is not a dictionary or the drop is not a string.\n",
        "    '''\n",
        "\n",
        "    if not isinstance(data, dict):\n",
        "      raise TypeError('Input data must be a dictionary.')\n",
        "    if not isinstance(drop, str):\n",
        "      raise TypeError('Drop must be a string.')\n",
        "\n",
        "    _data = data.copy()\n",
        "    if type(drop) == str and type(data) == dict:\n",
        "        if drop in data.keys():\n",
        "            _data.pop(drop)\n",
        "    return _data"
      ],
      "metadata": {
        "id": "U1diycpCKAkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Deletar Linha NaN\n",
        "###########################################\n",
        "def data_drop_na(data):\n",
        "    '''\n",
        "    Removes rows with missing or null values from the input dictionary.\n",
        "\n",
        "    It takes a dictionary as input and iterates over its rows; if a row contains a missing or null value (represented as \" \" or None), the function removes that row from the dictionary and returns the modified dictionary.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data: dict\n",
        "            The input dictionary in which each key represents a column, and the corresponding value is a data list for that column.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        dict\n",
        "            The modified dictionary with removed rows containing missing or null values.\n",
        "\n",
        "    Raises\n",
        "    ------------\n",
        "        TypeError\n",
        "            If the input data is not a dictionary.\n",
        "    '''\n",
        "\n",
        "    #Verificação de tipo de data inserido (type checking)\n",
        "    if not isinstance(data, dict):\n",
        "      raise TypeError('Input data must be a dictionary.')\n",
        "\n",
        "    _data = data.copy()\n",
        "    _columns = list(data.keys())\n",
        "    _num_rows = len(data[_columns[0]])\n",
        "\n",
        "    for _indice in range(_num_rows-1,-1,-1):\n",
        "        if \"\" in data_row(data, _indice) or None in data_row(data, _indice):\n",
        "            for _col in _columns:\n",
        "                _data[_col].pop(_indice)\n",
        "\n",
        "    return _data"
      ],
      "metadata": {
        "id": "yqWw5oJeWPzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Substituir valor NaN\n",
        "###########################################\n",
        "def data_fill_na(data, column:str, value):\n",
        "    '''\n",
        "    Replaces missing or null values in the input dictionary's specified column.\n",
        "\n",
        "    It takes a dictionary, a column name, and a value as input, then replaces any missing or null values (represented as \" \" or None) in the specified column with the provided value and returns the modified dictionary.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data: dict\n",
        "            The input dictionary in which each key represents a column, and the corresponding value is a data list for that column.\n",
        "        column: str\n",
        "            The name of the column in which to replace missing or null values.\n",
        "        value:\n",
        "            The value to replace missing or null values with.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        dict\n",
        "            The modified dictionary with missing or null values in the specified column replaced.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input data is not a dictionary or the specified column does not exist in the dictionary.\n",
        "    '''\n",
        "\n",
        "    if not isinstance(data, dict):\n",
        "        raise TypeError('Input data must be a dictionary.')\n",
        "    if column not in data:\n",
        "        raise TypeError('Specified column does not exist in the dictionary.')\n",
        "\n",
        "    _data = data.copy()\n",
        "    _num_rows = len(data[column])\n",
        "\n",
        "    for _indice in range(_num_rows):\n",
        "        if data[column][_indice] in (\"\", None):\n",
        "            data[column][_indice] = value\n",
        "\n",
        "    return _data"
      ],
      "metadata": {
        "id": "vLUtKzWwdu9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functions Statistics"
      ],
      "metadata": {
        "id": "wJVMHrcJVGFB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Retorna media\n",
        "###########################################\n",
        "def data_mean(data_list) -> float:\n",
        "    '''\n",
        "    Calculates the values in the input list's mean.\n",
        "\n",
        "    It takes a list as input and returns the values in the list's mean (average) (the mean is calculated as the sum divided by the number of values).\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data_list: list\n",
        "            The input list's numerical values.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        float\n",
        "            The values in the input list's mean.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input is not a list.\n",
        "    '''\n",
        "    if not type(data_list) is list:\n",
        "        raise TypeError('Input must be a list.')\n",
        "\n",
        "    _data = data_list\n",
        "    _data = [_ for _ in data_list if _ != \"\"]\n",
        "    return round(sum(_data)/len(_data), 3)"
      ],
      "metadata": {
        "id": "ikcwbP4HfATT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Retorna mediana\n",
        "###########################################\n",
        "def data_median(data_list) -> float:\n",
        "    '''\n",
        "    Calculates the values in the input list's median.\n",
        "\n",
        "    It takes a list as input and returns the median of the values in the list (the median is calculated by sorting the list and selecting the middle value if the list length is odd, or the average of the two central values if the list length is even).\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data_list: list\n",
        "            The numerical values' input list.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        float\n",
        "            The values in the input list's median.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input is not a list.\n",
        "    '''\n",
        "\n",
        "    if not type(data_list) is list:\n",
        "        raise TypeError(\"Deve passar uma lista como parametros.\")\n",
        "\n",
        "    _data = data_list\n",
        "    _data = sorted([_ for _ in data_list if _ != \"\"])\n",
        "\n",
        "    return _data[int(len(_data)/2)]"
      ],
      "metadata": {
        "id": "KCtv60sNhbef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functions Distances"
      ],
      "metadata": {
        "id": "trN6DPGpUthm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Distancia Euclidiana entre dois pontos\n",
        "###########################################\n",
        "def euclidian_distance(point_1, point_2):\n",
        "    '''\n",
        "    Calculates the Euclidean distance between two points (in a space with arbitrary dimension).\n",
        "\n",
        "    It takes two points (each represented as a list or tuple of coordinates) as input and calculates the Euclidean distance between them.\n",
        "    The Euclidean distance is calculated as the square root of the sum of the squared differences between the corresponding coordinates of the two points.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        point_1: list or tuple\n",
        "            The first point's coordinates (each element can be an int or a float).\n",
        "        point_2: list or tuple\n",
        "            The second point's coordinates (each element can be an int or a float).\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        float\n",
        "            The Euclidean distance between the two points.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        ValueError\n",
        "            If the two points do not have the same dimension number.\n",
        "    '''\n",
        "    # Verifica tipo de dados imputados\n",
        "    if len(point_1) != len(point_2):\n",
        "        raise ValueError('The points must have the same number of dimensions.')\n",
        "\n",
        "    distance = 0\n",
        "    for a, b in zip(point_1, point_2):\n",
        "        distance += (a-b)**2\n",
        "\n",
        "    return distance**(0.5)"
      ],
      "metadata": {
        "id": "qC5wfo3BuQ_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Distancia Manhattan entre dois pontos\n",
        "###########################################\n",
        "def manhattan_distance(point_1, point_2):\n",
        "    '''\n",
        "    Calculates the Manhattan distance between two points (in a space with arbitrary dimension).\n",
        "\n",
        "    It takes two points (each represented as a coordinates list or tuple) as input and calculates the Manhattan distance between them. The Manhattan distance is calculated as the sum of the absolute differences between corresponding coordinates of the two points.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        point_1: list or tuple\n",
        "            The first point's coordinates (each element can be an int or a float).\n",
        "        point_2: list or tuple\n",
        "            The second point's coordinates (each element can be an int or a float).\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        float\n",
        "            The Manhattan distance between the two points.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        ValueError\n",
        "            If the two points do not have the same number of dimensions.\n",
        "    '''\n",
        "    # Verifica tipo de dados imputados\n",
        "    if len(point_1) != len(point_2):\n",
        "        raise ValueError('The points must have the same number of dimensions.')\n",
        "\n",
        "    distance = 0\n",
        "    for a, b in zip(point_1, point_2):\n",
        "        distance += abs(a - b)\n",
        "\n",
        "    return distance"
      ],
      "metadata": {
        "id": "-8U6X2zSCmV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Distancia de Minkowski entre dois pontos\n",
        "###########################################\n",
        "def minkowski_distance(point_1, point_2, p=3):\n",
        "    '''\n",
        "    Calculates the Minkowski distance between two points.\n",
        "\n",
        "    It takes two points (each represented as a coordinates list or tuple) and a power parameter as input and calculates the Minkowski distance between them. The Minkowski distance is a generalization of the Euclidean and Manhattan distances. It is calculated as the p-th root of the absolute differences between corresponding coordinates of the two points (each raised to the power p) sum.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        point_1: list or tuple\n",
        "            The first point's coordinates (each element can be an int or a float).\n",
        "        point_2: list or tuple\n",
        "              The second point's coordinates (each element can be an int or a float).\n",
        "        p: int, optional\n",
        "            The power parameter. The default is 3.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        float\n",
        "            The Minkowski distance between the two points.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        ValueError\n",
        "            If the two points do not have the same number of dimensions.\n",
        "    '''\n",
        "    # Verifica tipo de dados imputados\n",
        "    if len(point_1) != len(point_2):\n",
        "        raise ValueError('The points must have the same number of dimensions.')\n",
        "\n",
        "    distance = sum(abs(a - b) ** p for a, b in zip(point_1, point_2))\n",
        "\n",
        "    return distance ** (1 / p)"
      ],
      "metadata": {
        "id": "XYr1rvhLEtvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functions KNN"
      ],
      "metadata": {
        "id": "bDWxbR8LiDH8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Normaliza dados do dataset\n",
        "###########################################\n",
        "def ml_normalize(data):\n",
        "    '''\n",
        "    Normalizes the values in each column of the input dictionary.\n",
        "\n",
        "    It takes a dictionary as input and normalizes the values in each column by subtracting the minimum value from each value and dividing by the range of the column; it then returns the modified dictionary.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data: dict\n",
        "            The input dictionary in which each key represents a column, and the corresponding value is a list of data for that column.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        dict\n",
        "            The modified dictionary with normalized values in each column.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input data is not a dictionary.\n",
        "    '''\n",
        "    # Verifica tipo de dados imputados\n",
        "    if not isinstance(data, dict):\n",
        "        raise TypeError('Input data must be a dictionary.')\n",
        "\n",
        "    _df = data.copy()\n",
        "    if type(data) == dict:\n",
        "        for attr in _df.keys():\n",
        "            ls = _df[attr]\n",
        "            maximo = max(ls)\n",
        "            minimo = min(ls)\n",
        "            f_normalize = lambda x: round((x - minimo) / (maximo - minimo), 4)\n",
        "            _df[attr] = list(map(f_normalize, ls))\n",
        "\n",
        "    return _df"
      ],
      "metadata": {
        "id": "yea7TyT3v_A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Padroniza dados do dataset\n",
        "###########################################\n",
        "def ml_standardize(data):\n",
        "    '''\n",
        "    Standardizes the values in each column of the input dictionary.\n",
        "\n",
        "    It takes a dictionary as input and standardizes the values in each column by subtracting the column mean from each value and then dividing by the column's standard deviation. The function then returns the modified dictionary.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data: dict\n",
        "            The input dictionary in which each key represents a column, and the corresponding value is a list of data for that column.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        dict\n",
        "            The modified dictionary (with standardized values in each column).\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input data is not a dictionary.\n",
        "    '''\n",
        "    # Verifica tipo de dados imputados\n",
        "    if not isinstance(data, dict):\n",
        "        raise TypeError('Input data must be a dictionary.')\n",
        "\n",
        "    _df = data.copy()\n",
        "    if type(data) == dict:\n",
        "        for attr in _df.keys():\n",
        "            ls = _df[attr]\n",
        "            mean_val = sum(ls) / len(ls)\n",
        "            std_dev = (sum((x - mean_val) ** 2 for x in ls) / len(ls)) ** 0.5\n",
        "            f_standardize = lambda x: round((x - mean_val) / std_dev, 4)\n",
        "            _df[attr] = list(map(f_standardize, ls))\n",
        "\n",
        "    return _df"
      ],
      "metadata": {
        "id": "BpyuZ4NVAFVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Separar dados de treino e dados de teste\n",
        "###########################################\n",
        "def ml_train_test_split(data_x, date_y, test_rate: float = 0.3):\n",
        "    '''\n",
        "    Splits the input data into training and testing sets.\n",
        "\n",
        "    It takes as input a features dictionary, a targets list, and a test rate.\n",
        "    It then splits the data into training and testing sets based on the test rate and returns the training features, the testing features, the training targets, and the testing targets.\n",
        "\n",
        "    Parameters\n",
        "    ------------\n",
        "        data_x: dict\n",
        "            The input features dictionary in which each key represents a feature, and the corresponding value is a list of data for that feature.\n",
        "        date_y: list\n",
        "            The input targets list.\n",
        "        test_rate: float, optional\n",
        "            The data's proportion to include in the test split.\n",
        "            The default is 0.3.\n",
        "\n",
        "    Returns\n",
        "    ------------\n",
        "        dict, dict, list, list\n",
        "            The training features (a dictionary with the same structure as data_x but with a subset of the data), the testing features (a dictionary with the same structure as data_x but with a different subset of the data), the training targets (a subset of date_y), and the testing targets (a different subset of date_y).\n",
        "\n",
        "    Raises\n",
        "    ------------\n",
        "        TypeError\n",
        "            If the input data_x is not a dictionary, or if the test_rate is not a float or is greater than 1.\n",
        "    '''\n",
        "    # Verifica tipo de dados imputados\n",
        "    if not type(data_x) is dict:\n",
        "        raise TypeError('Input data_x must be a dictionary.')\n",
        "    if not isinstance(test_rate, float) or test_rate > 1:\n",
        "        raise TypeError('Test rate must be a float less than or equal to 1.')\n",
        "\n",
        "    # Verifica taxa de teste (test_rate)\n",
        "    test_rate = test_rate if type(test_rate) == float and test_rate <= 1  else 0.3\n",
        "\n",
        "    # Quantifica amostra de teste e separa dados\n",
        "    _num_rows = len(date_y)\n",
        "    _num_test = int(_num_rows * test_rate)\n",
        "\n",
        "    # Separa amostra Y\n",
        "    y_test = date_y[:_num_test]\n",
        "    y_train = date_y[_num_test:]\n",
        "\n",
        "    # Separa amostra X\n",
        "    X_test = {name:[val for val in data_x[name][:_num_test]] for name in data_x.keys()}\n",
        "    X_train = {name:[val for val in data_x[name][_num_test:]] for name in data_x.keys()}\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "0zktiBUD1IiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################################################################################################\n",
        "# Grid Search - Testa diferentes valores K e distancias, e retorna os resultados.\n",
        "#########################################################################################################\n",
        "def ml_grid_search(X_train, y_train, k_values, distances=['euclidian']):\n",
        "    '''\n",
        "    Tests a k-nearest neighbors (KNN) model for each k-value specified in the input list.\n",
        "\n",
        "    It takes training features, training targets, a list of k-values, and a list of distances as input; then, it fits a KNN model to the training data and tests it on the testing data for each k-value and distance. It returns a list of dictionaries, each representing the results of the KNN model for a specific k-value and distance.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        X_train : dict\n",
        "            The input training features dictionary.\n",
        "        y_train: list\n",
        "            The input training targets list.\n",
        "        k_values: list\n",
        "            The input list of k-values to test.\n",
        "        distances: list, optional\n",
        "            The distances' input list to test. Defaults to ['euclidian'].\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        list\n",
        "            A list of dictionaries, each representing the KNN model's results for each specified k-value and distance.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input X_train is not a dictionary, the input y_train is not a list, the input k_values is not a list, or the input distances is not a list.\n",
        "    '''\n",
        "    # Verifica tipo de dados imputados\n",
        "    if not isinstance(X_train, dict) or not isinstance(X_test, dict):\n",
        "        raise TypeError('Input X_train and X_test must be dictionaries.')\n",
        "    if not isinstance(y_train, list) or not isinstance(y_test, list):\n",
        "        raise TypeError('Input y_train and y_test must be lists.')\n",
        "    if not isinstance(k_values, list):\n",
        "        raise TypeError('Input k_values must be a list.')\n",
        "    if not isinstance(distances, list):\n",
        "        raise TypeError('Input distances must be a list.')\n",
        "\n",
        "    # Testa a combinação dos k-values e das distances.\n",
        "    _return = []\n",
        "    for distance in distances:\n",
        "        _return += [{'k': k, 'score': ml_score_knn(knn), 'matrix': knn['confusion_matrix'], 'distance': knn['distance'], 'knn': knn}\n",
        "                        for k in k_values for knn in [ml_fit(X_train, y_train, k, distance)]]\n",
        "\n",
        "    return _return"
      ],
      "metadata": {
        "id": "-WC2Da5IoemD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Treinar KNN\n",
        "###########################################\n",
        "def ml_fit(X, y, n=3, distance_min=\"euclidian\"):\n",
        "    '''\n",
        "    Fits a k-nearest neighbors (KNN) model to the data.\n",
        "\n",
        "    It takes as input a features dictionary, a targets list, a specified number of neighbors, and a distance metric.\n",
        "    It then fits a KNN model to the data using the set number of neighbors and distance metric and returns a dictionary representing the model's fit.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        X: dict\n",
        "            The input features dictionary in which each key represents a feature, and the corresponding value is that feature's data list.\n",
        "        y: list\n",
        "            The input targets list.\n",
        "        n: int, optional\n",
        "            The number of neighbors to use in the KNN model.\n",
        "            The default is 3.\n",
        "        distance_min: str, optional\n",
        "            The metric distance to use in the KNN model. It can be 'euclidian,' 'minkowski,' or 'manhattan.'\n",
        "            The default is 'euclidian'.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        dict\n",
        "            A dictionary representing the KNN model's fit. The dictionary includes keys such as 'n_neighbors,' 'distance,' 'data_x_train,' 'data_y_train,' 'hit,' 'error,' 'confusion_matrix,' etc.\n",
        "            The exact keys may vary based on the implementation.)\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If input X is not a dictionary, input y is not a list; input distance_min is not one of the allowed values, or the lengths of X and y are unequal.\n",
        "    '''\n",
        "    # Verifica tipo de dados imputados\n",
        "    if not type(X) is dict: raise TypeError('Input X must be a dictionary.')\n",
        "    if not type(y) is list: raise TypeError('Input y must be a list.')\n",
        "    if not distance_min in ['euclidian', 'minkowski', 'manhattan']:\n",
        "        raise TypeError('Input distance_min must be one of the allowed values: \"euclidian\", \"minkowski\", \"manhattan\".')\n",
        "    if len(X[list(X.keys())[0]]) != len(y): raise TypeError('Input X and y must have the same length.')\n",
        "\n",
        "    # Armazena teste\n",
        "    _retrieval = {}\n",
        "    _retrieval['n_neighbors'] = n\n",
        "    _retrieval['distance'] = distance_min\n",
        "    _retrieval['data_x_train'] = X.copy()\n",
        "    _retrieval['data_y_train'] = y.copy()\n",
        "    _retrieval['hit'] = 0\n",
        "    _retrieval['error'] = 0\n",
        "    _retrieval['confusion_matrix'] = {col:{col2:0 for col2 in set(y)} for col in set(y)}\n",
        "    _retrieval['rounds'] = 0\n",
        "    _retrieval['num_rows'] = len(y)\n",
        "\n",
        "    # Número impar para desempate\n",
        "    n = n if n%2 == 1 else n+1\n",
        "\n",
        "    # Verifica qual será a distância será utilizada\n",
        "    if distance_min == \"minkowski\":\n",
        "        _fun_distance = minkowski_distance\n",
        "    elif distance_min == \"manhattan\":\n",
        "        _fun_distance = manhattan_distance\n",
        "    else:\n",
        "        _fun_distance = euclidian_distance\n",
        "\n",
        "    # Cria uma matriz com todos as linhas\n",
        "    _matrix_x = [data_row(X, i) for i in range(len(y))]\n",
        "\n",
        "    for index, y_expected in zip(range(len(y)), y):\n",
        "        line_a = _matrix_x[index]\n",
        "        list_distances = {}\n",
        "\n",
        "        # Calcula a distancia com todas as linhas\n",
        "        for row in range(len(y)):\n",
        "            # Conta rodadas\n",
        "            _retrieval['rounds'] += 1\n",
        "\n",
        "            if index == row:\n",
        "                continue\n",
        "            line_b = _matrix_x[row]\n",
        "\n",
        "            # Calcula distancia\n",
        "            distance = _fun_distance(line_a, line_b)\n",
        "            list_distances[distance] = y[row]\n",
        "\n",
        "        list_distances = dict(sorted(list_distances.items()))\n",
        "        list_distances = {_val[0]:_val[1] for _i, _val in zip(range(len(list_distances)), list_distances.items()) if _i < n}\n",
        "\n",
        "        _tally = {list(list_distances.values()).count(c) : c for c in set(list_distances.values())}\n",
        "        _tally = dict(sorted(_tally.items(), reverse=True))\n",
        "        _y_predict = list(_tally.values())[0]\n",
        "\n",
        "        _retrieval['confusion_matrix'][y_expected][_y_predict] += 1\n",
        "\n",
        "        if _y_predict == y_expected:\n",
        "            _retrieval['hit'] += 1\n",
        "        else:\n",
        "            _retrieval['error'] += 1\n",
        "\n",
        "    return _retrieval"
      ],
      "metadata": {
        "id": "iaR_ap_skgiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Preditor KNN\n",
        "###########################################\n",
        "def ml_predict(knn_fit, X_test, y_test):\n",
        "    '''\n",
        "    Fits a k-nearest neighbors (KNN) model to the data.\n",
        "\n",
        "    It takes a dictionary representing a fitted KNN model, a features dictionary for the test data, and a targets list for the test data as input.\n",
        "    It then uses the fitted KNN model to make predictions on the test data and returns a dictionary representing the model's predictions.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "        knn_fit: dict\n",
        "\t          The input dictionary representing a fitted KNN model.\n",
        "        X_test: dict\n",
        "\t          The input features dictionary in which each key represents a feature, and the corresponding value is that feature's data list.\n",
        "        y_test: list\n",
        "            The input targets list for the test data.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        dict\n",
        "            A dictionary representing the KNN model's prediction.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input knn_fit is not a dictionary, the input X_test is not a dictionary, the input y_test is not a list, or the lengths of X_test and y_test are unequal.\n",
        "    '''\n",
        "    # Verifica tipo de dados imputados\n",
        "    if not type(knn_fit) is dict: raise TypeError('Input knn_fit must be a dictionary.')\n",
        "    if not type(X_test) is dict: raise TypeError('Input X_test must be a dictionary.')\n",
        "    if not type(y_test) is list: raise TypeError('Input y_test must be a list.')\n",
        "    if len(X_test[list(X_test.keys())[0]]) != len(y_test): raise TypeError('Input X_test and y_test must have the same length.')\n",
        "\n",
        "    # Dados usados no treino\n",
        "    _n = knn_fit['n_neighbors']\n",
        "    _distance_min = knn_fit['distance']\n",
        "    _X_train = knn_fit['data_x_train']\n",
        "    _y_train = knn_fit['data_y_train']\n",
        "\n",
        "    # Dados usados no Test\n",
        "    _num_rows = len(y_test)\n",
        "\n",
        "    # Armazena teste\n",
        "    _retrieval = {}\n",
        "    _retrieval['n_neighbors'] = _n\n",
        "    _retrieval['distance'] = _distance_min\n",
        "    _retrieval['data_x_test'] = X_test.copy()\n",
        "    _retrieval['data_y_test'] = y_test.copy()\n",
        "    _retrieval['data_y_predict'] = []\n",
        "    _retrieval['hit'] = 0\n",
        "    _retrieval['error'] = 0\n",
        "    _retrieval['confusion_matrix'] = {col:{col2:0 for col2 in set(_y_train)} for col in set(_y_train)}\n",
        "    _retrieval['num_rows'] = _num_rows\n",
        "    _retrieval['rounds'] = 0\n",
        "\n",
        "    # Número impar para desempate\n",
        "    _n = _n if _n%2 == 1 else _n+1\n",
        "\n",
        "    # Verifica qual será a distância será utilizada\n",
        "    if _distance_min == \"minkowski\":\n",
        "        _fun_distance = minkowski_distance\n",
        "    elif _distance_min == \"manhattan\":\n",
        "        _fun_distance = manhattan_distance\n",
        "    else:\n",
        "        _fun_distance = euclidian_distance\n",
        "\n",
        "    # Cria uma matriz com todos as linhas\n",
        "    _matrix_x_train = [data_row(_X_train, i) for i in range(len(_y_train))]\n",
        "    _matrix_x_test = [data_row(X_test, i) for i in range(len(y_test))]\n",
        "\n",
        "    for index, y_expected in zip(range(_num_rows), y_test):\n",
        "        line_a = _matrix_x_test[index]\n",
        "        list_distances = {}\n",
        "\n",
        "        # Calcula a distancia com todas as linhas\n",
        "        for row in range(len(_y_train)):\n",
        "            # Conta rodadas\n",
        "            _retrieval['rounds'] += 1\n",
        "\n",
        "            # Captura linha de Comparação\n",
        "            line_b = _matrix_x_train[row]\n",
        "\n",
        "            # Calcula a distância\n",
        "            distance = _fun_distance(line_a, line_b)\n",
        "            list_distances[distance] = _y_train[row]\n",
        "\n",
        "        list_distances = dict(sorted(list_distances.items()))\n",
        "        list_distances = {_val[0]:_val[1] for _i, _val in zip(range(len(list_distances)), list_distances.items()) if _i < _n}\n",
        "\n",
        "        _tally = {list(list_distances.values()).count(c) : c for c in set(list_distances.values())}\n",
        "\n",
        "\n",
        "        _tally = {list(list_distances.values()).count(c) : c for c in {_ for _ in list_distances.values()}}\n",
        "        _tally = dict(sorted(_tally.items(), reverse=True))\n",
        "        _y_predict = list(_tally.values())[0]\n",
        "\n",
        "        _retrieval['data_y_predict'].append(_y_predict)\n",
        "        _retrieval['confusion_matrix'][y_expected][_y_predict] += 1\n",
        "\n",
        "        if _y_predict == y_expected:\n",
        "            _retrieval['hit'] += 1\n",
        "        else:\n",
        "            _retrieval['error'] += 1\n",
        "\n",
        "    return _retrieval"
      ],
      "metadata": {
        "id": "9tM7r2JA0ATz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Functions Metrics"
      ],
      "metadata": {
        "id": "sXWnBSF_UWfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Calcular Score\n",
        "###########################################\n",
        "def ml_score_knn(data_fit):\n",
        "    '''\n",
        "    Calculates a k-nearest neighbors (KNN) model accuracy score.\n",
        "\n",
        "    It takes a dictionary as input, representing a KNN model's fit results.\n",
        "    The dictionary should contain the keys 'hit' and 'num_rows.\n",
        "    'hit' represents the number of correct predictions made by the model, and 'num_rows' the predictions' total number.\n",
        "    It calculates the score as the ratio of 'hit' to 'num_rows' and returns this score.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data_fit: dict\n",
        "            The input dictionary representing a KNN model fit.\n",
        "                It should contain the keys 'hit' and 'num_rows', where 'hit' is the number of correct predictions and 'num_rows' is the total number of predictions.\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        float\n",
        "            The KNN model's accuracy score (calculated as the ratio of 'hit' to 'num_rows').\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input data_fit is not a dictionary.\n",
        "    '''\n",
        "    # Verifica tipo de dados imputados\n",
        "    if not isinstance(data_fit, dict):\n",
        "        raise TypeError('Input data_fit must be a dictionary.')\n",
        "\n",
        "    _retorno = data_fit\n",
        "    return round(_retorno['hit']/_retorno['num_rows'], 4)"
      ],
      "metadata": {
        "id": "XSyN1FLlI6Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Metrics - Classification Report\n",
        "###########################################\n",
        "def metric_classification_report(data_fit, label={}):\n",
        "    '''\n",
        "    Generates the input dictionary's classification report.\n",
        "\n",
        "    It takes a dictionary as input, representing a fitted model's results; calculates precision, recall, f1-score, and support for each data class; and prints a classification report.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data_fit: dict\n",
        "            The input dictionary that represents a fitted model's results. It should contain a 'confusion_matrix' key (a dictionary representing the model confusion matrix).\n",
        "        label: dict\n",
        "            The input dictionary that represents a label of dataset.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input data_fit is not a dictionary.\n",
        "    '''\n",
        "    # Verifica tipo de dados imputados\n",
        "    if not type(data_fit) is dict: raise TypeError('data_fit must be a dictionary.')\n",
        "    if not type(label) is dict: raise TypeError('label must be a dictionary.')\n",
        "\n",
        "    _confusion_matrix  = data_fit['confusion_matrix']\n",
        "    _columns = list(_confusion_matrix.keys())\n",
        "    _dim = len(max(_columns, key=len)) if type(_columns[0]) == str else 13\n",
        "    _dimension_col = _dim if _dim > 13 else 13\n",
        "\n",
        "    _var_print = f\"{' ':^{_dimension_col}}{'precision':>11}{'recall':>11}{'f1-score':>11}{'support':>11}\\n\\n\"\n",
        "\n",
        "    _support_list = []\n",
        "    _precision_list = []\n",
        "    _recall_list = []\n",
        "    _f1_score_list = []\n",
        "\n",
        "    for _col in _columns:\n",
        "        _support = sum(_confusion_matrix[_col].values())\n",
        "        _precision = _confusion_matrix[_col][_col] / _support\n",
        "        _recall = _confusion_matrix[_col][_col] / sum([_confusion_matrix[_col2][_col] for _col2 in _columns])\n",
        "        _f1_score = 2 * _precision * _recall / (_precision + _recall)\n",
        "\n",
        "        _col = label[_col] if _col in list(label.keys()) else _col\n",
        "\n",
        "        _var_print += f\"{_col:>{_dimension_col}}\"\n",
        "        _var_print += f\"{str(round(_precision, 5)):>11}\"\n",
        "        _var_print += f\"{str(round(_recall, 5)):>11}\"\n",
        "        _var_print += f\"{str(round(_f1_score, 5)):>11}\"\n",
        "        _var_print += f\"{str(round(_support, 5)):>11}\"\n",
        "        _var_print += \"\\n\"\n",
        "\n",
        "        _support_list.append(_support)\n",
        "        _precision_list.append(_precision)\n",
        "        _recall_list.append(_recall)\n",
        "        _f1_score_list.append(_f1_score)\n",
        "\n",
        "    _mean_precision = round(sum(_precision_list)/len(_precision_list), 5)\n",
        "    _mean_recall = round(sum(_recall_list)/len(_recall_list), 5)\n",
        "    _mean_f1_score = round(sum(_f1_score_list)/len(_f1_score_list), 5)\n",
        "\n",
        "    print(_var_print)\n",
        "    print(f\"{'avg':>{_dimension_col}}{_mean_precision:>11}{_mean_recall:>11}{_mean_f1_score:>11}{sum(_support_list):>11}\\n\")"
      ],
      "metadata": {
        "id": "YKPfll51ZPiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###########################################\n",
        "# Metrics - Accuracy\n",
        "###########################################\n",
        "def metric_accuracy(data_fit):\n",
        "    '''\n",
        "    Calculates a model's accuracy based on the input dictionary.\n",
        "\n",
        "    It takes a dictionary that represents a fitted model's results as input and uses the 'confusion_matrix' key in the dictionary to calculate and return the model's accuracy.\n",
        "\n",
        "    Parameters\n",
        "    -------------\n",
        "        data_fit: dict\n",
        "            The input dictionary representing the fitted model's results; it should contain a 'confusion_matrix' key (a dictionary representing the model's confusion matrix).\n",
        "\n",
        "    Returns\n",
        "    -------------\n",
        "        float\n",
        "            The model's accuracy.\n",
        "\n",
        "    Raises\n",
        "    -------------\n",
        "        TypeError\n",
        "            If the input data_fit is not a dictionary.\n",
        "    '''\n",
        "    # Verifica tipo de dados imputados\n",
        "    if not type(data_fit) is dict:\n",
        "        raise TypeError('data_fit must be a dictionary.')\n",
        "\n",
        "    _confusion_matrix  = data_fit['confusion_matrix']\n",
        "    _columns = list(_confusion_matrix.keys())\n",
        "\n",
        "    _true_predict = sum([_confusion_matrix[_col][_col] for _col in _columns])\n",
        "    _total_support = sum([sum(_confusion_matrix[_col].values()) for _col in _columns])\n",
        "\n",
        "    return _true_predict / _total_support"
      ],
      "metadata": {
        "id": "t9ygy1oWZe5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Execução KNN**"
      ],
      "metadata": {
        "id": "1CU2BwfChn73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega dados\n",
        "data_test = read_csv('water_potability.csv', delimiter=\",\")"
      ],
      "metadata": {
        "id": "BydBFuVsmaDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar tipo\n",
        "type(data_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRZ_Y5dPO3E0",
        "outputId": "aa5434cc-6631-4e97-f608-8306c5abed8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 180
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualização de Dados\n",
        "data_view(data_test, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbseIzZMG2Bb",
        "outputId": "d85b8856-7251-40c1-a74a-5f92873b15df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------------------------------------------------------------\n",
            "|                                                        VIEW DATASET                                                         |\n",
            "-------------------------------------------------------------------------------------------------------------------------------\n",
            "|  n  |    ph     |  Hardne   |  Solids   |  Chlora   |  Sulfat   |  Conduc   |  Organi   |  Trihal   |  Turbid   |  Potabi   |\n",
            "-------------------------------------------------------------------------------------------------------------------------------\n",
            "|  0  |           | 204.89045 | 20791.318 | 7.3002118 | 368.51644 | 564.30865 | 10.379783 | 86.990970 | 2.9631353 |     0     |\n",
            "|  1  | 3.7160800 | 129.42292 | 18630.057 | 6.6352458 |           | 592.88535 | 15.180013 | 56.329076 | 4.5006562 |     0     |\n",
            "|  2  | 8.0991241 | 224.23625 | 19909.541 | 9.2758836 |           | 418.60621 | 16.868636 | 66.420092 | 3.0559337 |     0     |\n",
            "|  3  | 8.3167658 | 214.37339 | 22018.417 | 8.0593323 | 356.88613 | 363.26651 | 18.436524 | 100.34167 | 4.6287705 |     0     |\n",
            "|  4  | 9.0922234 | 181.10150 | 17978.986 | 6.5465999 | 310.13573 | 398.41081 | 11.558279 | 31.997992 | 4.0750754 |     0     |\n",
            "| ..  |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |\n",
            "-------------------------------------------------------------------------------------------------------------------------------\n",
            "|  col/row: (10, 3276) | limit view: 5                                                                                        |\n",
            "-------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Informações do dataset\n",
        "data_info(data_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dOOdyniy_WG",
        "outputId": "225ceafe-4a51-45c4-ccc6-c8801e0482fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'columns': ['ph',\n",
              "  'Hardness',\n",
              "  'Solids',\n",
              "  'Chloramines',\n",
              "  'Sulfate',\n",
              "  'Conductivity',\n",
              "  'Organic_carbon',\n",
              "  'Trihalomethanes',\n",
              "  'Turbidity',\n",
              "  'Potability'],\n",
              " 'num_columns': 10,\n",
              " 'num_rows': 3276,\n",
              " 'dimension': (10, 3276),\n",
              " 'info_col___________________ph': ('null   491', 'type    mixed'),\n",
              " 'info_col_____________Hardness': ('null     0', \"type   <class 'float'>\"),\n",
              " 'info_col_______________Solids': ('null     0', \"type   <class 'float'>\"),\n",
              " 'info_col__________Chloramines': ('null     0', \"type   <class 'float'>\"),\n",
              " 'info_col______________Sulfate': ('null   781', 'type    mixed'),\n",
              " 'info_col_________Conductivity': ('null     0', \"type   <class 'float'>\"),\n",
              " 'info_col_______Organic_carbon': ('null     0', \"type   <class 'float'>\"),\n",
              " 'info_col______Trihalomethanes': ('null   162', 'type    mixed'),\n",
              " 'info_col____________Turbidity': ('null     0', \"type   <class 'float'>\"),\n",
              " 'info_col___________Potability': ('null     0', \"type   <class 'int'>\")}"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Substituir Valores pela média\n",
        "data_fill = data_fill_na(data_test,'ph',data_mean(data_test['ph']))\n",
        "data_fill = data_fill_na(data_test,'Sulfate',data_mean(data_test['Sulfate']))\n",
        "data_fill = data_fill_na(data_test,'Trihalomethanes',data_mean(data_test['Trihalomethanes']))\n",
        "data_view(data_fill, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSa8BlD8jn6h",
        "outputId": "9c40a26f-5cd0-4ead-9ade-3d8d6de46432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------------------------------------------------------------\n",
            "|                                                        VIEW DATASET                                                         |\n",
            "-------------------------------------------------------------------------------------------------------------------------------\n",
            "|  n  |    ph     |  Hardne   |  Solids   |  Chlora   |  Sulfat   |  Conduc   |  Organi   |  Trihal   |  Turbid   |  Potabi   |\n",
            "-------------------------------------------------------------------------------------------------------------------------------\n",
            "|  0  |   7.081   | 204.89045 | 20791.318 | 7.3002118 | 368.51644 | 564.30865 | 10.379783 | 86.990970 | 2.9631353 |     0     |\n",
            "|  1  | 3.7160800 | 129.42292 | 18630.057 | 6.6352458 |  333.776  | 592.88535 | 15.180013 | 56.329076 | 4.5006562 |     0     |\n",
            "|  2  | 8.0991241 | 224.23625 | 19909.541 | 9.2758836 |  333.776  | 418.60621 | 16.868636 | 66.420092 | 3.0559337 |     0     |\n",
            "|  3  | 8.3167658 | 214.37339 | 22018.417 | 8.0593323 | 356.88613 | 363.26651 | 18.436524 | 100.34167 | 4.6287705 |     0     |\n",
            "|  4  | 9.0922234 | 181.10150 | 17978.986 | 6.5465999 | 310.13573 | 398.41081 | 11.558279 | 31.997992 | 4.0750754 |     0     |\n",
            "| ..  |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |\n",
            "-------------------------------------------------------------------------------------------------------------------------------\n",
            "|  col/row: (10, 3276) | limit view: 5                                                                                        |\n",
            "-------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Opção - Remover Valores ausentes (caso fosse necessário)\n",
        "# _data_ex = data_drop_na(_data_ex)\n",
        "# data_view(_data_ex, 5)"
      ],
      "metadata": {
        "id": "5LVuQeCPkPo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descreve os dados\n",
        "print(data_describe(data_fill))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqcgCIDFzMwp",
        "outputId": "7197ea93-51f5-4468-96cc-6ae266ae4ad3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Analysis                      ph            Hardness              Solids         Chloramines             Sulfate        Conductivity      Organic_carbon     Trihalomethanes           Turbidity          Potability                   \n",
            "        Tipo             <class 'float'>     <class 'float'>     <class 'float'>     <class 'float'>     <class 'float'>     <class 'float'>     <class 'float'>     <class 'float'>     <class 'float'>       <class 'int'>                   \n",
            "        Quant                       3276                3276                3276                3276                3276                3276                3276                3276                3276                3276                   \n",
            "        Máximo                      14.0             323.124         61227.19601              13.127           481.03064           753.34262                28.3               124.0               6.739                   1                   \n",
            "        Mínimo                       0.0              47.432           320.94261               0.352               129.0           181.48375                 2.2               0.738                1.45                   0                   \n",
            "        Soma                 23196.78369        643306.46895      72118167.11543         23332.57878       1093449.61864        1396247.9426         46797.56253        217514.20824         12995.19149                1278                   \n",
            "        Amplitude                   14.0             275.692          60906.2534              12.775           352.03064           571.85887                26.1             123.262               5.289                   1                   \n",
            "        Média                    7.08083            196.3695         22014.09253             7.12228           333.77583           426.20511            14.28497            66.39628             3.96679             0.39011                   \n",
            "        Mediana                    7.081           196.98238         20933.51275             7.13044             333.776           421.89008             14.2193              66.396             3.95509                   0                   \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Slice data_x and data_y\n",
        "dataset_cp = data_fill.copy()\n",
        "data_y = dataset_cp.pop('Potability')\n",
        "data_x = dataset_cp.copy()"
      ],
      "metadata": {
        "id": "6aHbw-IzqnXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Conta dados\n",
        "data_value_counts(data_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qm_0NJqIfoz",
        "outputId": "f7455138-3278-46d5-cfd8-790ec3b23d6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 1278, 0: 1998}"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_view(data_x,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6BJiFU7ridm",
        "outputId": "21535e51-c3f4-4815-c52f-bc77f822065f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------------------------------------------------\n",
            "|                                                  VIEW DATASET                                                   |\n",
            "-------------------------------------------------------------------------------------------------------------------\n",
            "|  n  |    ph     |  Hardne   |  Solids   |  Chlora   |  Sulfat   |  Conduc   |  Organi   |  Trihal   |  Turbid   |\n",
            "-------------------------------------------------------------------------------------------------------------------\n",
            "|  0  |   7.081   | 204.89045 | 20791.318 | 7.3002118 | 368.51644 | 564.30865 | 10.379783 | 86.990970 | 2.9631353 |\n",
            "|  1  | 3.7160800 | 129.42292 | 18630.057 | 6.6352458 |  333.776  | 592.88535 | 15.180013 | 56.329076 | 4.5006562 |\n",
            "|  2  | 8.0991241 | 224.23625 | 19909.541 | 9.2758836 |  333.776  | 418.60621 | 16.868636 | 66.420092 | 3.0559337 |\n",
            "|  3  | 8.3167658 | 214.37339 | 22018.417 | 8.0593323 | 356.88613 | 363.26651 | 18.436524 | 100.34167 | 4.6287705 |\n",
            "|  4  | 9.0922234 | 181.10150 | 17978.986 | 6.5465999 | 310.13573 | 398.41081 | 11.558279 | 31.997992 | 4.0750754 |\n",
            "| ..  |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |\n",
            "-------------------------------------------------------------------------------------------------------------------\n",
            "|  col/row: (9, 3276) | limit view: 5                                                                             |\n",
            "-------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normaliza os dados\n",
        "data_x_normaliado = ml_normalize(data_x)\n",
        "data_view(data_x_normaliado, 5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJs4cOb8r9yv",
        "outputId": "b517dcac-c4e0-48ef-9ce9-c09ca39e4fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------------------------------------------------------\n",
            "|                                                  VIEW DATASET                                                   |\n",
            "-------------------------------------------------------------------------------------------------------------------\n",
            "|  n  |    ph     |  Hardne   |  Solids   |  Chlora   |  Sulfat   |  Conduc   |  Organi   |  Trihal   |  Turbid   |\n",
            "-------------------------------------------------------------------------------------------------------------------\n",
            "|  0  |  0.5058   |  0.5711   |  0.3361   |  0.5439   |  0.6804   |  0.6694   |  0.3134   |  0.6998   |  0.2861   |\n",
            "|  1  |  0.2654   |  0.2974   |  0.3006   |  0.4918   |  0.5817   |  0.7194   |  0.4973   |   0.451   |  0.5768   |\n",
            "|  2  |  0.5785   |  0.6413   |  0.3216   |  0.6985   |  0.5817   |  0.4147   |   0.562   |  0.5329   |  0.3036   |\n",
            "|  3  |  0.5941   |  0.6055   |  0.3562   |  0.6033   |  0.6473   |  0.3179   |  0.6221   |  0.8081   |   0.601   |\n",
            "|  4  |  0.6494   |  0.4849   |  0.2899   |  0.4849   |  0.5145   |  0.3793   |  0.3586   |  0.2536   |  0.4963   |\n",
            "| ..  |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |    ...    |\n",
            "-------------------------------------------------------------------------------------------------------------------\n",
            "|  col/row: (9, 3276) | limit view: 5                                                                             |\n",
            "-------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Separa dados com ml_train_test_split()\n",
        "X_train, X_test, y_train, y_test = ml_train_test_split(data_x_normaliado, data_y, 0.25)\n",
        "print(len(X_train[list(X_train.keys())[0]]), len(X_test[list(X_test.keys())[0]]), len(y_train), len(y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of22HYcMxNPQ",
        "outputId": "6a40f866-47fb-45f3-a227-237b9c364c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2457 819 2457 819\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# distance_min: 'euclidian', 'minkowski', 'manhattan'\n",
        "knn_fit = ml_fit(X_train, y_train, n=50, distance_min='euclidian')\n",
        "print('Score:', ml_score_knn(knn_fit)*100, \"%\")\n",
        "print('Rounds:', knn_fit['rounds'])"
      ],
      "metadata": {
        "id": "RHDOiQQi66fT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "743b13f3-c717-4e82-dff3-1c617d5f3cb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 65.36 %\n",
            "Rounds: 6036849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Semelhante ao Grid Search - testar diferentes valores K\n",
        "k_values = [20, 30, 40, 50, 60]\n",
        "distances = ['euclidian', 'minkowski']\n",
        "grid_search = ml_grid_search(X_train, y_train, k_values, distances)\n",
        "\n",
        "# Armazena o melhor score\n",
        "best_score = sorted(grid_search, key=lambda x: x['score'], reverse=True)[0]\n",
        "\n",
        "# Visualizar os resultados do Grid Search\n",
        "for index, row in zip(range(1, len(grid_search)+1), sorted(grid_search, key=lambda x: x['score'], reverse=True)):\n",
        "    print(index, f\"K: {row['k']}, Score: {row['score']}, Distance: {row['distance']}\", '<- Best Score' if index == 1 else '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Txflr3KcHPQG",
        "outputId": "69a07155-2fd0-4bd2-f277-9fdcec90bc6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 K: 50, Score: 0.6536, Distance: euclidian <- Best Score\n",
            "2 K: 30, Score: 0.6524, Distance: euclidian \n",
            "3 K: 40, Score: 0.6524, Distance: euclidian \n",
            "4 K: 30, Score: 0.6508, Distance: minkowski \n",
            "5 K: 40, Score: 0.6479, Distance: minkowski \n",
            "6 K: 50, Score: 0.6455, Distance: minkowski \n",
            "7 K: 60, Score: 0.6398, Distance: euclidian \n",
            "8 K: 20, Score: 0.6374, Distance: minkowski \n",
            "9 K: 60, Score: 0.637, Distance: minkowski \n",
            "10 K: 20, Score: 0.6345, Distance: euclidian \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisa a Matriz de Confusão do best_score\n",
        "metric_classification_report(best_score['knn'], {0:\"No Drinkable\", 1:\"Drinkable\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGfRg2wqbqfi",
        "outputId": "92e6be2a-0564-49ce-944e-07d284d097a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision     recall   f1-score    support\n",
            "\n",
            " No Drinkable    0.95928    0.64526    0.77154       1498\n",
            "    Drinkable    0.17623    0.73478    0.28427        959\n",
            "\n",
            "          avg    0.56775    0.69002    0.52791       2457\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediz os valores no X_test\n",
        "knn_predict = ml_predict(knn_fit, X_test, y_test)\n",
        "print('Score:', ml_score_knn(knn_predict)*100, \"%\")\n",
        "print('Rounds:', knn_predict['rounds'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2ibGksCcYqU",
        "outputId": "8ce5d1e4-cd94-4600-c176-3b3e190717fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score: 62.27 %\n",
            "Rounds: 2012283\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisa a Matriz de Confusão\n",
        "metric_classification_report(knn_predict, {0:\"No Drinkable\", 1:\"Drinkable\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQAModtGcv-2",
        "outputId": "4ec5652a-ae94-4cc8-855e-ebf2753994c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision     recall   f1-score    support\n",
            "\n",
            " No Drinkable      0.938    0.62784    0.75221        500\n",
            "    Drinkable    0.12853    0.56944    0.20972        319\n",
            "\n",
            "          avg    0.53326    0.59864    0.48096        819\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisa a Acurácia\n",
        "print(\"Accuracy: \", round(metric_accuracy(knn_predict)*100, 5), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBb-7MGnecy-",
        "outputId": "961a70bd-24db-43ab-a31d-f11901a4e806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  62.27106 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparando com Scikit-learn"
      ],
      "metadata": {
        "id": "Y5aBVA387Omc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "df_base = pd.read_csv('water_potability.csv')"
      ],
      "metadata": {
        "id": "0ULhH__Y4EOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_base.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qSV6A4Km4zTF",
        "outputId": "e7db64cd-fe2e-45aa-d20a-087e9c5d76ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
              "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
              "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
              "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
              "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
              "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
              "\n",
              "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
              "0       10.379783        86.990970   2.963135           0  \n",
              "1       15.180013        56.329076   4.500656           0  \n",
              "2       16.868637        66.420093   3.055934           0  \n",
              "3       18.436524       100.341674   4.628771           0  \n",
              "4       11.558279        31.997993   4.075075           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-378696f3-7b29-4b36-9335-a5731e1b0464\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ph</th>\n",
              "      <th>Hardness</th>\n",
              "      <th>Solids</th>\n",
              "      <th>Chloramines</th>\n",
              "      <th>Sulfate</th>\n",
              "      <th>Conductivity</th>\n",
              "      <th>Organic_carbon</th>\n",
              "      <th>Trihalomethanes</th>\n",
              "      <th>Turbidity</th>\n",
              "      <th>Potability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>204.890455</td>\n",
              "      <td>20791.318981</td>\n",
              "      <td>7.300212</td>\n",
              "      <td>368.516441</td>\n",
              "      <td>564.308654</td>\n",
              "      <td>10.379783</td>\n",
              "      <td>86.990970</td>\n",
              "      <td>2.963135</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.716080</td>\n",
              "      <td>129.422921</td>\n",
              "      <td>18630.057858</td>\n",
              "      <td>6.635246</td>\n",
              "      <td>NaN</td>\n",
              "      <td>592.885359</td>\n",
              "      <td>15.180013</td>\n",
              "      <td>56.329076</td>\n",
              "      <td>4.500656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8.099124</td>\n",
              "      <td>224.236259</td>\n",
              "      <td>19909.541732</td>\n",
              "      <td>9.275884</td>\n",
              "      <td>NaN</td>\n",
              "      <td>418.606213</td>\n",
              "      <td>16.868637</td>\n",
              "      <td>66.420093</td>\n",
              "      <td>3.055934</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.316766</td>\n",
              "      <td>214.373394</td>\n",
              "      <td>22018.417441</td>\n",
              "      <td>8.059332</td>\n",
              "      <td>356.886136</td>\n",
              "      <td>363.266516</td>\n",
              "      <td>18.436524</td>\n",
              "      <td>100.341674</td>\n",
              "      <td>4.628771</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9.092223</td>\n",
              "      <td>181.101509</td>\n",
              "      <td>17978.986339</td>\n",
              "      <td>6.546600</td>\n",
              "      <td>310.135738</td>\n",
              "      <td>398.410813</td>\n",
              "      <td>11.558279</td>\n",
              "      <td>31.997993</td>\n",
              "      <td>4.075075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-378696f3-7b29-4b36-9335-a5731e1b0464')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-378696f3-7b29-4b36-9335-a5731e1b0464 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-378696f3-7b29-4b36-9335-a5731e1b0464');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1a16aa7e-7e23-49cb-b767-7dc71d677543\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1a16aa7e-7e23-49cb-b767-7dc71d677543')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1a16aa7e-7e23-49cb-b767-7dc71d677543 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_base.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWlpC6zr4012",
        "outputId": "7562042b-158c-4b57-ca3e-fefce5ddc060"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               2785 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          2495 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3114 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col in df_base.columns:\n",
        "    df_base[col] = df_base[col].fillna(df_base[col].mean())\n",
        "\n",
        "df_base.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMaE2LAw4P0A",
        "outputId": "678162d6-9a51-4368-cd87-d497d0df1ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3276 entries, 0 to 3275\n",
            "Data columns (total 10 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   ph               3276 non-null   float64\n",
            " 1   Hardness         3276 non-null   float64\n",
            " 2   Solids           3276 non-null   float64\n",
            " 3   Chloramines      3276 non-null   float64\n",
            " 4   Sulfate          3276 non-null   float64\n",
            " 5   Conductivity     3276 non-null   float64\n",
            " 6   Organic_carbon   3276 non-null   float64\n",
            " 7   Trihalomethanes  3276 non-null   float64\n",
            " 8   Turbidity        3276 non-null   float64\n",
            " 9   Potability       3276 non-null   int64  \n",
            "dtypes: float64(9), int64(1)\n",
            "memory usage: 256.1 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_y = df_base['Potability']\n",
        "df_x = df_base.drop('Potability', axis=1)"
      ],
      "metadata": {
        "id": "y3lZGrxD5YK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size=0.25)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "AEDsIIPc5y8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zvk5o_tneEEU",
        "outputId": "cdef6ae0-cc94-4587-8f94-3aa929c734b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2457, 819, 2457, 819)"
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "93G0Lm5cxVPL",
        "outputId": "0b34052d-bb21-41df-a2f9-6a3b9746f10f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=3)"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", round(accuracy*100, 5), \"%\")\n",
        "print(\"Precision:\", round(precision*100, 5), \"%\")\n",
        "print(\"Recall:\", round(recall*100, 5), \"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELWp4mLDxczJ",
        "outputId": "60069994-e3e2-47d1-840e-fbb3f41ef6d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 60.56166 %\n",
            "Precision: 45.4902 %\n",
            "Recall: 38.66667 %\n"
          ]
        }
      ]
    }
  ]
}